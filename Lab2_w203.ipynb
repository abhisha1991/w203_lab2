{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - W203 - Statistics for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission by Jude Kavalam, Harshit Patel, Abhi Sharma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"dplyr\")\n",
    "library(dplyr)\n",
    "install.packages(\"rcompanion\")\n",
    "library(rcompanion)\n",
    "install.packages(\"repr\")\n",
    "library(repr)\n",
    "install.packages(\"effsize\")\n",
    "library(effsize)\n",
    "\n",
    "# set standard height and width for images displayed\n",
    "options(repr.plot.width=5, repr.plot.height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data = function() {\n",
    "    wd = getwd()\n",
    "    return (read.csv(paste(wd, \"/\", \"anes_pilot_2018.csv\", sep=\"\")))    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data context: https://electionstudies.org/wp-content/uploads/2019/02/anes_pilot_2018_userguidecodebook.pdf \n",
    "\n",
    "Questionnaire: https://electionstudies.org/wp-content/uploads/2018/12/anes_pilot_2018_questionnaire.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Functions\n",
    "\n",
    "Here are some generic functions that help slice the data in convenient ways which can be used across all the research questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_skp = function(df, skp_prefix, skp_values) {\n",
    "    skp_col = paste(skp_prefix, \"_skp\", sep = \"\")\n",
    "    return (df %>% filter(df[, skp_col] %in% skp_values))\n",
    "}\n",
    "\n",
    "# Usage\n",
    "# x = filter_skp(data, \"ftpolice\", c(0,1))\n",
    "# nrow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_timing = function(df, timing_prefix, time_threshold) {\n",
    "    timing_col = paste(timing_prefix, \"_page_timing\", sep= \"\")\n",
    "    return (df %>% filter(df[, timing_col] <= time_threshold))\n",
    "}\n",
    "\n",
    "# Usage\n",
    "# x = filter_timing(data, \"ftpolice\", 10)\n",
    "# nrow(x)\n",
    "# summary(x$ftpolice_page_timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_honest = function(df, honest_vals) {\n",
    "    return (df %>% filter(df[, \"honest\"] %in% honest_vals))\n",
    "}\n",
    "\n",
    "#Freq. Numeric Label\n",
    "#37      1     Never\n",
    "#46      2     Some of the time\n",
    "#90      3     About half the time\n",
    "#215     4     Most of the time\n",
    "#2112    5     Always\n",
    "\n",
    "# Usage\n",
    "# x = filter_honest(data, c(1))\n",
    "# nrow(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_nonserious = function(df, ns_vals) {\n",
    "    return (df %>% filter(df[, \"nonserious\"] %in% ns_vals))\n",
    "}\n",
    "\n",
    "#Freq. Numeric Label\n",
    "#2007    1     Never\n",
    "#157     2     Some of the time\n",
    "#109     3     About half the time\n",
    "#55      4     Most of the time\n",
    "#172     5     Always\n",
    "\n",
    "# Usage\n",
    "# x = filter_nonserious(data, c(1))\n",
    "# nrow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Do US voters have more respect for the police or for journalists?\n",
    "\n",
    "### Introduce your topic briefly. (5 points)\n",
    "Will need to use ftpolice (How would you rate the police?) and ftjournal (How would you rate journalists?)\n",
    "\n",
    "These are measured on a thermal scale (ordinal) from 0 to 100. The variables capturing the rating are:\n",
    "1. ftpolice_therm for ftpolice\n",
    "2. ftjournal_therm for ftjournal\n",
    "\n",
    "The key assumption we're making here is that these ratings (ftpolice and ftjournal) are being used to measure \"respect levels\" for these professions. This is a reasonable assumption given that there are no other variables to capture this sentiment.\n",
    "\n",
    "Its important to call out the ordinal nature of the scale and how a value of 55 for respondent 1 may differ from the same value of 55 for respondent 2. In other words, **the same score for a group (say police) may have different meanings for different respondents.**\n",
    "\n",
    "However, the score of ftpolice = 90 and ftjournal = 55 for a particular respondent shows that the respondent in question has more respect for police than journalists. In other words, **different scores for the same respondent on the 2 groups have comparable interpretation.** \n",
    "\n",
    "Hence, the data captured is in pairs. For each respondent, we have 2 scores and we can compare these scores to form proportions of voters that like the police vs journalists.\n",
    "\n",
    "### Perform an exploratory data analysis (EDA) of the relevant variables. (5 points)\n",
    " \n",
    "There are certain variables of interest along which we can slice the number of respondents we consider in the test:\n",
    "\n",
    "First we create a base data set (called q1_data):\n",
    "\n",
    "**1. honest** <br/>\n",
    "This represents respondents who answered the survey honestly. To get reliable results, **we will only consider respondents who are honest for this question.** It is important that we consider responses where people feel honest when answering questions regarding respect for professionals in police vs journalism.\n",
    "\n",
    "**2. ftpolice_page_timing and ftjournal_page_timing** <br/>\n",
    "This represents the time taken for a respondent to answer the corresponding questions (ftpolice and ftjournal). The reason why this may have been potentially interesting is because if a respondent takes too long to answer the question, then he / she maynot be sure about how they feel about the police / journalists. The 90th percentile for each variable seems to be within 12 seconds, which seems like a reasonable time to answer the question \"without hestitation\". **We will further explore this variable and discard responses > (say) 30 seconds.**\n",
    "\n",
    "**3. nonserious** <br/>\n",
    "This represents respondents who had degrees of nonserious-ness in the survey. **We will consider respondents who have values for nonserious=[1,2,3] as our entire population.** We want only serious candidates to be considered when answering a question like this. \n",
    "\n",
    "Next, we consider further slicing our base data set (q1_data) based on certain attributes:\n",
    "\n",
    "**1. ftpolice_skp and ftjournal_skp** <br/>\n",
    "This represents the variable where a candidate was asked a question, but decided to skip the question the first time around. This may reveal the hesitant nature of the respondent to answer the question directly. Hence, we will check the percentage of our base data set to determine how many respondents skipped these questions. If this distribution is fairly large, we will consider doing 2 sets of tests (where skp=0 vs considering all skp values).\n",
    "\n",
    "**2. nonserious** <br/>\n",
    "We will check what percentage of the base data set population is very serious (ie, nonserious=1) and will make a decision to further conduct a separate test with only a very serious population (or not).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for ftpolice_page_timing\n",
    "d = get_data()\n",
    "paste(\"Summary for ftpolice_page_timing\")\n",
    "summary(d$ftpolice_page_timing)\n",
    "\n",
    "paste(\"Number of ftpolice_page_timing > 30 seconds\")\n",
    "nrow(d[d$ftpolice_page_timing > 30,])\n",
    "# note that we will remove the 33 rows that are > 30 seconds in response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for ftjournal_page_timing\n",
    "paste(\"Summary for ftjournal_page_timing\")\n",
    "summary(d$ftjournal_page_timing)\n",
    "\n",
    "paste(\"Number of ftjournal_page_timing >= 30 seconds\")\n",
    "nrow(d[d$ftjournal_page_timing > 30,])\n",
    "# note that we will remove the 29 rows that are > 30 seconds in response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for honest\n",
    "paste(\"Summary for honest\")\n",
    "summary(d$honest)\n",
    "\n",
    "paste(\"Percentage of always honest respondents\")\n",
    "as.numeric(nrow(d[d$honest == 5,]) / nrow(d)) * 100\n",
    "\n",
    "hist(d$honest, main = \"Histogram of Honest variable\", xlab = \"Honest label\", col = \"lightblue\", border = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for nonserious\n",
    "paste(\"Summary for nonserious\")\n",
    "summary(d$nonserious)\n",
    "\n",
    "paste(\"Percentage of nonserious=[1,2,3] respondents\")\n",
    "as.numeric(nrow(d[d$nonserious %in%  c(1,2,3),]) / nrow(d)) * 100\n",
    "\n",
    "hist(d$nonserious, main = \"Histogram of Nonserious variable\", xlab = \"Nonserious label\", col = \"lightblue\", border = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's construct our base data set (q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base data set \n",
    "q1_data = get_data()\n",
    "\n",
    "# consider only \"always honest\" respondents \n",
    "q1_data = filter_honest(q1_data, c(5))\n",
    "\n",
    "# consider respondents with _page_timing less than equal to 30 seconds\n",
    "q1_data = filter_timing(q1_data, \"ftpolice\", 30)\n",
    "q1_data = filter_timing(q1_data, \"ftjournal\", 30)\n",
    "\n",
    "# consider only respondents with nonseriousness levels 1,2,3 \n",
    "q1_data = filter_nonserious(q1_data, c(1,2,3))\n",
    "\n",
    "nrow(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We further slice our data on the basis of very serious vs our population of serious [1,2,3] respondents\n",
    "q1_data_serious = filter_nonserious(q1_data, c(1))\n",
    "nrow(q1_data_serious)/nrow(q1_data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We notice that the very serious (nonserious=1) population is a large portion of the data we are working with.  So we will decide NOT to conduct separate tests for very serious (nonserious=1) vs semi serious (nonserious=[1,2,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we further investigate the ftpolice_skp and ftjournal_skp variables\n",
    "\n",
    "# EDA for ftpolice_skp\n",
    "paste(\"Summary for ftpolice_skp\")\n",
    "summary(q1_data$ftpolice_skp)\n",
    "\n",
    "paste(\"Percentage of non-zero ftpolice_skp\")\n",
    "as.numeric(nrow(q1_data[q1_data$ftpolice_skp %in%  c(1),]) / nrow(q1_data)) * 100\n",
    "# < 1% of the respondents chose to skip the ftpolice question. This shows the respondents are not hesitant!\n",
    "\n",
    "# EDA for ftjournal_skp\n",
    "paste(\"Summary for ftjournal_skp\")\n",
    "summary(q1_data$ftjournal_skp)\n",
    "\n",
    "paste(\"Percentage of non-zero ftjournal_skp\")\n",
    "as.numeric(nrow(q1_data[q1_data$ftjournal_skp %in%  c(1,2),]) / nrow(q1_data)) * 100\n",
    "# < 1% of the respondents chose to skip the ftjournal question. This shows the respondents are not hesitant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We conclude that there were very few (< 1%) of respondents from our base data set that chose to skip the ftpolice or ftjournal question. So we will NOT conduct further tests based on skp=0 vs all skp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Analysis of ftpolice and ftjournal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Summary for ftpolice\")\n",
    "summary(q1_data$ftpolice)\n",
    "\n",
    "paste(\"Unique values for ftpolice\")\n",
    "unique(q1_data$ftpolice)\n",
    "# we observe there are no \"invalid\" values (negative values, values outside of 0-100)\n",
    "\n",
    "hist(q1_data$ftpolice, xlab = \"ftpolice score\", main = \"Histogram of ftpolice\", col = \"lightblue\", border = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the ordinal and likert nature of the ftpolice score, we cannot construct any distribution of the variable. \n",
    "#### However, we notice a skewness in high respect for police based on the histogram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Summary for ftjournal\")\n",
    "summary(q1_data$ftjournal)\n",
    "\n",
    "paste(\"Unique values for ftjournal\")\n",
    "unique(q1_data$ftjournal)\n",
    "# we observe there are negative values for ftjournal, which is also evident from the histogram\n",
    "\n",
    "hist(q1_data$ftjournal, xlab = \"ftjournal score\", main = \"Histogram of ftjournal\", col = \"lightblue\", border = \"black\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the ordinal and likert nature of the ftjournal score, we cannot construct any distribution of the variable. \n",
    "#### However, we notice an almost bi-modal nature in ftjournal score - people are divided on their respect levels for journalists  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we notice there are values for ftjournal < 0, so we need to remove these rows as they are missing values\n",
    "paste(\"ftjournal scores less than 0\")\n",
    "nrow(q1_data[q1_data$ftjournal < 0,])\n",
    "\n",
    "paste(\"ftjournal scores >= 0\")\n",
    "q1_data = q1_data[q1_data$ftjournal >= 0,]\n",
    "nrow(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check on having the right values for our tests\n",
    "nrow(q1_data[q1_data$ftjournal >= 0 & q1_data$ftpolice >= 0,]) == nrow(q1_data)\n",
    "nrow(q1_data[q1_data$ftjournal <= 100 & q1_data$ftpolice <= 100,]) == nrow(q1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your EDA, select an appropriate hypothesis test. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few observations:\n",
    "\n",
    "1. The measurements are likert variables, we cannot say that the difference between 5 and 6 is the same between 89 and 90. These are NOT metric values.\n",
    "2. Having said that, a score of 89 is more favorable than a score of 5 **(ordinal behavior)**.\n",
    "3. However, these are **comparable in measurement across groups** because they are measured on the SAME scale and measured against the SAME audience.\n",
    "4. The distribution of both ftpolice and ftjournal cannot be determined due to likert nature. **So we will have to use \"non parametric tests\"**.\n",
    "5. Note that we are NOT interested in \"how much more\" do US voters respect police vs journalists. We are interested in \"which group is respected more\". Specifically, **we are interested in the sign of the test** where the sign indicates which side US voters respect more. Note that because we use non-parametric signed tests, we are throwing out information of the likert scale.\n",
    "6. These are **paired measurements against the same individual across 2 groups** - journalists and policemen.\n",
    "7. Notice sample size is large, n > 40.\n",
    "8. Hence, we will conduct a paired non parametric test, specifically, the **Signed test for Dependent Samples**\n",
    "9. We **could have performed a Wilcoxon Signed-Rank test for paired data**, but that will answer the question - \"How much more / less are the police respected compared to journalists by US Voters?\". That answers a different question from the one being asked, although it would have more statistical power than the signed test. \n",
    "\n",
    "Assumptions:\n",
    "\n",
    "1. We can assume as per instructions in the lab that each pair of ftpolice and ftjournal, say (p, j) are IID.\n",
    "2. We do have an ordinal scale for measurement (0 to 100 therm scale)\n",
    "\n",
    "Consequence:\n",
    "1. Because we are throwing away all our likert information, we **lose some statistical power with the signed test.**\n",
    "\n",
    "Hypothesis:\n",
    "\n",
    "1. Let plus = number of total events of seeing ftpolice > ftjournal\n",
    "2. Let minus = number of total events of seeing ftpolice < ftjournal\n",
    "3. Here, plus ~ Binomial(n, 0.5)\n",
    "\n",
    "**Ho: Prob(plus) = Prob(minus)**\n",
    "\n",
    "**Ha: Prob(plus) != Prob(minus)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_hat = nrow(q1_data[q1_data$ftpolice == q1_data$ftjournal,])\n",
    "plus_hat = nrow(q1_data[q1_data$ftpolice > q1_data$ftjournal,])\n",
    "minus_hat = nrow(q1_data[q1_data$ftpolice < q1_data$ftjournal,])\n",
    "total_hat = as.numeric(equal_hat + plus_hat + minus_hat)\n",
    "# ignore equal scores of ftjournal and ftpolice for binomial test\n",
    "n = total_hat - equal_hat\n",
    "\n",
    "paste(\"ftpolice == ftjournal:\", equal_hat)\n",
    "paste(\"ftpolice > ftjournal:\", plus_hat)\n",
    "paste(\"ftpolice < ftjournal:\", minus_hat)\n",
    "paste(\"total:\", total_hat)\n",
    "paste(\"total - equal:\", n)\n",
    "\n",
    "# binomial test\n",
    "p = 0.5\n",
    "mean = n * p\n",
    "threshold = abs(plus_hat - mean)\n",
    "paste(\"The mean:\", mean)\n",
    "paste(\"The threshold:\", threshold)\n",
    "# p value is prob that |plus - mean| >= threshold\n",
    "# to find p value\n",
    "# P(plus - 910.5 >= 122.5) and P(910.5 - plus >= 122.5)\n",
    "# P(plus >= 1033) and P(plus <= 788)\n",
    "\n",
    "binom.test(x = c(plus_hat, minus_hat), n, p = 0.5, alternative = c(\"two.sided\"), conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above shows that we reject the null hypothesis as the p value is very small at 5% level of significance. We see that probabilities of the number of successes in the 2 groups is NOT equal.\n",
    "\n",
    "#### We see probability of success is around 56%. This implies that the US voters do like policemen more than journalists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infact, if we did the test one sided, where the alternative is that \n",
    "# Prob(# fav. ftpolice scores) > Prob(# fav. ftjournal scores) \n",
    "binom.test(x = c(plus_hat, minus_hat), n, p = 0.5, alternative = c(\"greater\"), conf.level = 0.95)\n",
    "# this further shows that the alternative hypothesis is favorable, \n",
    "# where probability of police respect cases is more than probability of journalism respect cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Effect Size For Signed Test**\n",
    "\n",
    "1. We can think of the proportion of police population as the effect size\n",
    "2. We can also think of (plus_hat - minus_hat) / n as the effect size\n",
    "3. Since n is large, the effect size is actually significant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_hat/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plus_hat - minus_hat)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can conclude that there is a real difference between the respect levels for police vs journalists. US voters respect the police more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Are Republican voters older or younger than Democratic voters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce your topic briefly.  (5 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables operationized\n",
    "There are four variables I am using to validate the hypothesis that Republican voters are younger than Democrat voters\n",
    "<dl>\n",
    "  <dt>honest</dt>\n",
    "  <dd><em>Question: </em>\"How often would you say you answered the questions honestly on this survey.\"\n",
    "  <br>The range of responses are 1-5 which corelate from Never - Always. I have restricted the observations to only those who answer <em>always (5)</em></dd>\n",
    "  <br>\n",
    "  <dt>pid1r</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Republican, a Democrat, an\n",
    "independent, or what?\"</dd>\n",
    "  <br>  \n",
    "  <dt>pid1d</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Democrat, a Republican, an\n",
    "independent, or what?\"<br>\n",
    "      As you can see this is essentially the same question with the just the <em>order</em> of the party name changed. The two responses I am interested in are 1 or 2. This corresponds to the first or second party mentioned in the questions\n",
    "  </dd>\n",
    "  <br>\n",
    "    \n",
    "  <dt>birthyr</dt>\n",
    "  <dd><em>Question: </em>“In what year were you born?”<br>\n",
    "      The response to this question was the year of birth. Since this survey was taken in 2018, for calculation of age, to determine age, we used:\n",
    "      \n",
    "```python\n",
    "2018 - birthyr \n",
    "```\n",
    "  </dd>\n",
    "  <dt>Gaps</dt>\n",
    "  <dd>1. There is an assumption that a \"Republican voter\" (i.e. someone who voted for the Republican candidate) also identfies as a Republican, and similarly for Democrat voter. It is quite likely that many who identify with one party, can vote for another party</dd>\n",
    "  <br>\n",
    "    <dd>2. There is another variable <em>nonserious</em> that while interesting, brought with it social implications that were beyond the scope for this exercise and I decided to ignore that variable</dd>\n",
    "    \n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform an exploratory data analysis (EDA) of the relevant variables. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv( \"anes_pilot_2018.csv\")\n",
    "# apply honestly filter\n",
    "hon_respondents = data[data$honest == 5,]\n",
    "paste(cat(\"Number of honest respondents: :\", nrow(hon_respondents)))\n",
    "\n",
    "honest.code <- c(Never=1, `Some of the time`=2, `Half of the time`=3, `Most of the time`=4,  Always=5)\n",
    "h_responses = names(honest.code)[match(data$honest, honest.code)]\n",
    "paste(cat(\"First 6 reponses in honest variable are:\",\"\\n\",head(h_responses)))\n",
    "\n",
    "pid1d.code <- c( Democrat=1, Republican=2, independent=3, 'something else'=4)\n",
    "pid1r.code <- c( Republican=1, Democrat=2, independent=3, 'something else'=4)\n",
    "p1did_responses = names(pid1d.code)[match(data$pid1d, pid1d.code)]\n",
    "p1dir_responses = names(pid1r.code)[match(data$pid1r, pid1r.code)]\n",
    "\n",
    "paste(cat(\"First 6 reponses in pid1d are: \", head(p1did_responses)))\n",
    "paste(cat(\"First 6 reponses in pid1r are:\", head(p1dir_responses)))\n",
    "paste(cat(\"Ages of first 6 respondents calculated to be: \", head(2018-data[, c(\"birthyr\")])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your EDA, select an appropriate hypothesis test.  (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_honest_reps = rbind(data[data$pid1r==1 & data$honest==5,], data[data$pid1d==2 & data$honest==5,])\n",
    "all_honest_dems = rbind(data[data$pid1r==2 & data$honest==5,], data[data$pid1d==1 & data$honest==5,])\n",
    "paste(cat(\"Number of observerations or Republicans: \", nrow(all_honest_reps)))\n",
    "paste(cat(\"Number of observerations or Democrats: \", nrow(all_honest_dems)))\n",
    "\n",
    "\n",
    "ages_of_reps = 2018-all_honest_reps[,c('birthyr')]\n",
    "ages_of_dems = 2018-all_honest_dems[,c('birthyr')]\n",
    "hist(ages_of_reps, col=\"red\")\n",
    "hist(ages_of_dems, col=\"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data are normally distributed, we can use a parametric test and since we are comparing the means of two samples, we can use the Welches Two Sample t-test (IOW, \"unpaired\" or \"independent samples\" t-test)\n",
    "\n",
    "H0: There is no significant difference between the mean of the ages of democrats vs republicans\n",
    "\n",
    "HA: The mean of the ages of one of the groups is significantly higher than the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(ages_of_dems, ages_of_reps, alternative = \"two.sided\", 0, paired = FALSE, var.equal = FALSE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this test, we can say with 95% confidence that there is no significant difference between the means of the ages of the Republican voters and the Democratic voters\n",
    "\n",
    "The manimum difference of the mean can be as low as -2.40 or has high as 1.19.\n",
    "\n",
    "The sample means are 52.33 for republicans and 52.92 for democrats.\n",
    "    \n",
    "Based on this we <em>do not have enough evidence to reject the null hypothesis</em> that there is no difference between the means.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen.d(ages_of_dems, ages_of_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CohensD test returns an estimate of 0.036 which indicates that the effect is negligible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Do a majority of independent voters believe that the federal investigations of Russian election interference are baseless?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce your topic briefly.  (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how your variables are operationalized. Comment on any gaps that you can identify between your operational definitions and the concepts you are trying to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables operationized\n",
    "There are seven variables I am using to validate the hypothesis that the federal investigations of Russian election interference are baseless.\n",
    "<dl>\n",
    "  <dt>honest</dt>\n",
    "  <dd><em>Question: </em>\"How often would you say you answered the questions honestly on this survey.\"\n",
    "  <br>The range of responses are 1-5 which corelate from Never - Always. I have restricted the observations to remove those who answered <em>Never (1)</em></dd>\n",
    "  <br>\n",
    "    \n",
    "  <dt>nonserious</dt>\n",
    "  <dd><em>Question: </em>\"We sometimes find people don't always take surveys seriously, instead providing funny or\n",
    "insincere answers. How often would you say that you were not serious in answering\n",
    "questions on this survey?\"\n",
    "  <br>The range of responses are 1-5 which corelate from Never - Always. I have restricted the observations to remove those who answered <em>Always (5)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  <dt>pid1r</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Republican, a Democrat, an\n",
    "independent, or what?\"</dd>\n",
    "  <br>  \n",
    "  <dt>pid1d</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Democrat, a Republican, an\n",
    "independent, or what?\"<br>\n",
    "      As you can see this is essentially the same question with the just the <em>order</em> of the party name changed. The response I am interested is for both questions is 3 i.e. Independent.\n",
    "  </dd>\n",
    "  <br>\n",
    "  \n",
    "   <dt>pid7x</dt>\n",
    "  <dd><em>Question: </em>\"Party ID summary\"\n",
    "  <br>The range of responses are from -7 to 7. I have restricted the observations to include those who answered <em>Independent (4)</em></dd>\n",
    "  <br>  \n",
    "    \n",
    "   <dt>russia16</dt>\n",
    "  <dd><em>Question: </em>\"Do you think the Russian government probably interfered in the 2016 presidential election\n",
    "to try to help Donald Trump win, or do you think this probably did not happen?\"\n",
    "  <br>I am checking their view on Russia's involvement, on the sample set I got from above 5 variables<em>This probably did not happen(2)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  <dt>coord16</dt>\n",
    "  <dd><em>Question: </em>\"Do you think Donald Trump’s 2016 campaign probably coordinated with the Russians, or do\n",
    "you think his campaign probably did not do this?\"\n",
    "  <br>I am checking their view on Russia's involvement, on the sample set I got from first 5 variables <em>Probably did not (2)</em></dd>\n",
    "  <br>\n",
    "    \n",
    " \n",
    "  <dt>Gaps</dt>\n",
    "  <dd>1. There is an assumption that a \"Independent voter\" (i.e. someone who is neither Republican nor Democrat) is indeed Independent and doesn't have bias in his opinion. </dd>\n",
    "  <br>\n",
    "    <dd>2. The variables <em>honest</em> and <em>nonserious</em> are both very subjective to people. We are including people in our sample space who might or might not be honest/nonserious. We have only neglected the people who were clear they didn't take the questionaire seriousloy.</dd>\n",
    "    \n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform an exploratory data analysis (EDA) of the relevant variables. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For mutate\n",
    "library(dplyr)\n",
    "#For cohend\n",
    "library(effsize)\n",
    "#For test\n",
    "library(BSDA)\n",
    "\n",
    "I = read.csv(\"/Users/hmpatel/Desktop/prepare/AIML/MIDS/W203 Statistics/lab2/anes_pilot_2018.csv\")\n",
    "\n",
    "unique(I$russia16)\n",
    "unique(I$coord16)\n",
    "\n",
    "#Replace -7 with 0 and create two new columns \n",
    "I_n <- mutate(\n",
    "  I, russia16_n = as.numeric(ifelse(substr(I$russia16,0,1) == \"-\", 0, substr(I$russia16,0,1))),\n",
    "  coord16_n = as.numeric(ifelse(substr(I$coord16,0,1) == \"-\", 0, substr(I$coord16,0,1))))\n",
    "\n",
    "# Checking all 3 tags and finding the Independent voters. Tried finding common of all 3, but found no one \n",
    "I_n_2 <- mutate(subset(I_n,substr(pid7x,0,1) == '4' | substr(pid1d,0,1) == '3' | substr(pid1r,0,1) == '3' , \n",
    "         select = c(pid7x,pid1d,pid1r,russia16_n,coord16_n)), indep_voters = 'Independent')\n",
    "\n",
    "#Checking honesty and seriousness as well and who didnt skip answer about Russia involvement question\n",
    "I_n_3 <- mutate(subset(I_n,(substr(pid7x,0,1) == '4' | substr(pid1d,0,1) == '3' | substr(pid1r,0,1) == '3') & \n",
    "        (honest != '1' & nonserious != '5') & (russia16_n != '0' & coord16_n != '0'), \n",
    "        select = c(pid7x,pid1d,pid1r,russia16_n,coord16_n, honest, nonserious)), indep_voters = 'Independent')\n",
    "\n",
    "c(mean(I_n_3$russia16_n), mean(I_n_3$coord16_n))\n",
    "summary(I_n_3$russia16_n)\n",
    "summary(I_n_3$coord16_n)\n",
    "I_n_4 <- I_n_3\n",
    "I_n_4$russ_view <- ifelse((I_n_3$russia16_n == '2' | I_n_3$coord16_n == '2'), 1, 0)\n",
    "\n",
    "I_n_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your EDA, select an appropriate hypothesis test.  (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hpothesis:\n",
    "\n",
    "Do a majority of independent voters believe that the federal investigations of Russian election interference are baseless\n",
    "\n",
    "Let R1 = Number of Independent voters believe Russia was not involved\n",
    "\n",
    "Let R2 = Number of Independent voters believe Russia was involved\n",
    "\n",
    "H0 = Null hypothesis, R1 = R2\n",
    "\n",
    "Ha = Alternative hypothesis, R1 not equal R2 \n",
    "\n",
    "(We can check if R1 > R2 or R2 > R1 later using 1 tailed test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- length(I_n_4$russ_view)\n",
    "plus_hat = nrow(I_n_4[I_n_4$russ_view == 1,])\n",
    "minus_hat = nrow(I_n_4[I_n_4$russ_view == 0,])\n",
    "\n",
    "plus_hat\n",
    "minus_hat\n",
    "\n",
    "#We can do a z.test here with mu=0.5 but since the russ_view is a Binamial experiment here, \n",
    "#we can use the binom.test which is even more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.test(x = c(plus_hat, minus_hat), n, p = 0.5, alternative = c(\"two.sided\"), conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 811 Independent Voters, 431 believe that federal investigations of Russian election interference are baseless.\n",
    "\n",
    "P-value is 0.079 >0.05 which implies we fail to reject the Null Hypothesis \n",
    "\n",
    "We dont have enough statistical significance to say that a majority of Independent voters beleive that\n",
    "the federal investigations of Russian election interference are baseless\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohend test\n",
    "#Yet to do"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
