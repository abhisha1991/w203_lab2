{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - W203 - Statistics for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission by Jude Kavalam, Harshit Patel, Abhi Sharma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"dplyr\")\n",
    "library(dplyr)\n",
    "install.packages(\"rcompanion\")\n",
    "library(rcompanion)\n",
    "install.packages(\"repr\")\n",
    "library(repr)\n",
    "install.packages(\"effsize\")\n",
    "library(effsize)\n",
    "install.packages(\"BSDA\")\n",
    "library(BSDA)\n",
    "install.packages(\"car\")\n",
    "library(car)\n",
    "# set standard height and width for images displayed\n",
    "options(repr.plot.width=5, repr.plot.height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data = function() {\n",
    "    wd = getwd()\n",
    "    return (read.csv(paste(wd, \"/\", \"anes_pilot_2018.csv\", sep=\"\")))    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data context: https://electionstudies.org/wp-content/uploads/2019/02/anes_pilot_2018_userguidecodebook.pdf \n",
    "\n",
    "Questionnaire: https://electionstudies.org/wp-content/uploads/2018/12/anes_pilot_2018_questionnaire.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Functions\n",
    "\n",
    "Here are some generic functions that help slice the data in convenient ways which can be used across all the research questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_skp = function(df, skp_prefix, skp_values) {\n",
    "    skp_col = paste(skp_prefix, \"_skp\", sep = \"\")\n",
    "    return (df %>% filter(df[, skp_col] %in% skp_values))\n",
    "}\n",
    "\n",
    "# Usage\n",
    "# x = filter_skp(data, \"ftpolice\", c(0,1))\n",
    "# nrow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_col = function(df, colname, colvalues) {\n",
    "    return (df %>% filter(df[, colname] %in% colvalues))\n",
    "}\n",
    "\n",
    "# Usage\n",
    "# x = filter_var(data, \"geangry\", c(1,2))\n",
    "# nrow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_timing = function(df, timing_prefix, time_threshold) {\n",
    "    timing_col = paste(timing_prefix, \"_page_timing\", sep= \"\")\n",
    "    return (df %>% filter(df[, timing_col] <= time_threshold))\n",
    "}\n",
    "\n",
    "# Usage\n",
    "# x = filter_timing(data, \"ftpolice\", 10)\n",
    "# nrow(x)\n",
    "# summary(x$ftpolice_page_timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_honest = function(df, honest_vals) {\n",
    "    return (df %>% filter(df[, \"honest\"] %in% honest_vals))\n",
    "}\n",
    "\n",
    "#Freq. Numeric Label\n",
    "#37      1     Never\n",
    "#46      2     Some of the time\n",
    "#90      3     About half the time\n",
    "#215     4     Most of the time\n",
    "#2112    5     Always\n",
    "\n",
    "# Usage\n",
    "# x = filter_honest(data, c(1))\n",
    "# nrow(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_nonserious = function(df, ns_vals) {\n",
    "    return (df %>% filter(df[, \"nonserious\"] %in% ns_vals))\n",
    "}\n",
    "\n",
    "#Freq. Numeric Label\n",
    "#2007    1     Never\n",
    "#157     2     Some of the time\n",
    "#109     3     About half the time\n",
    "#55      4     Most of the time\n",
    "#172     5     Always\n",
    "\n",
    "# Usage\n",
    "# x = filter_nonserious(data, c(1))\n",
    "# nrow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Do US voters have more respect for the police or for journalists?\n",
    "\n",
    "### Introduce your topic briefly. (5 points)\n",
    "Will need to use ftpolice (How would you rate the police?) and ftjournal (How would you rate journalists?)\n",
    "\n",
    "These are measured on a thermal scale (ordinal) from 0 to 100. The variables capturing the rating are:\n",
    "1. ftpolice_therm for ftpolice\n",
    "2. ftjournal_therm for ftjournal\n",
    "\n",
    "The key assumption we're making here is that these ratings (ftpolice and ftjournal) are being used to measure \"respect levels\" for these professions. This is a reasonable assumption given that there are no other variables to capture this sentiment.\n",
    "\n",
    "Its important to call out the ordinal nature of the scale and how a value of 55 for respondent 1 may differ from the same value of 55 for respondent 2. In other words, **the same score for a group (say police) may have different meanings for different respondents.**\n",
    "\n",
    "However, the score of ftpolice = 90 and ftjournal = 55 for a particular respondent shows that the respondent in question has more respect for police than journalists. In other words, **different scores for the same respondent on the 2 groups have comparable interpretation.** \n",
    "\n",
    "Hence, the data captured is in pairs. For each respondent, we have 2 scores and we can compare these scores to form proportions of voters that like the police vs journalists.\n",
    "\n",
    "### Perform an exploratory data analysis (EDA) of the relevant variables. (5 points)\n",
    " \n",
    "There are certain variables of interest along which we can slice the number of respondents we consider in the test:\n",
    "\n",
    "First we create a base data set (called q1_data):\n",
    "\n",
    "**1. honest** <br/>\n",
    "This represents respondents who answered the survey honestly. To get reliable results, **we will only consider respondents who are honest for this question.** It is important that we consider responses where people feel honest when answering questions regarding respect for professionals in police vs journalism.\n",
    "\n",
    "**2. ftpolice_page_timing and ftjournal_page_timing** <br/>\n",
    "This represents the time taken for a respondent to answer the corresponding questions (ftpolice and ftjournal). The reason why this may have been potentially interesting is because if a respondent takes too long to answer the question, then he / she maynot be sure about how they feel about the police / journalists. The 90th percentile for each variable seems to be within 12 seconds, which seems like a reasonable time to answer the question \"without hestitation\". **We will further explore this variable and discard responses > (say) 30 seconds.**\n",
    "\n",
    "**3. nonserious** <br/>\n",
    "This represents respondents who had degrees of nonserious-ness in the survey. **We will consider respondents who have values for nonserious=[1,2,3] as our entire population.** We want only serious candidates to be considered when answering a question like this. \n",
    "\n",
    "Next, we consider further slicing our base data set (q1_data) based on certain attributes:\n",
    "\n",
    "**1. ftpolice_skp and ftjournal_skp** <br/>\n",
    "This represents the variable where a candidate was asked a question, but decided to skip the question the first time around. This may reveal the hesitant nature of the respondent to answer the question directly. Hence, we will check the percentage of our base data set to determine how many respondents skipped these questions. If this distribution is fairly large, we will consider doing 2 sets of tests (where skp=0 vs considering all skp values).\n",
    "\n",
    "**2. nonserious** <br/>\n",
    "We will check what percentage of the base data set population is very serious (ie, nonserious=1) and will make a decision to further conduct a separate test with only a very serious population (or not).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for ftpolice_page_timing\n",
    "d = get_data()\n",
    "paste(\"Summary for ftpolice_page_timing\")\n",
    "summary(d$ftpolice_page_timing)\n",
    "\n",
    "paste(\"Number of ftpolice_page_timing > 30 seconds\")\n",
    "nrow(d[d$ftpolice_page_timing > 30,])\n",
    "# note that we will remove the 33 rows that are > 30 seconds in response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for ftjournal_page_timing\n",
    "paste(\"Summary for ftjournal_page_timing\")\n",
    "summary(d$ftjournal_page_timing)\n",
    "\n",
    "paste(\"Number of ftjournal_page_timing >= 30 seconds\")\n",
    "nrow(d[d$ftjournal_page_timing > 30,])\n",
    "# note that we will remove the 29 rows that are > 30 seconds in response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for honest\n",
    "paste(\"Summary for honest\")\n",
    "summary(d$honest)\n",
    "\n",
    "paste(\"Percentage of always honest respondents\")\n",
    "as.numeric(nrow(d[d$honest == 5,]) / nrow(d)) * 100\n",
    "\n",
    "hist(d$honest, main = \"Histogram of Honest variable\", xlab = \"Honest label\", col = \"lightblue\", border = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for nonserious\n",
    "paste(\"Summary for nonserious\")\n",
    "summary(d$nonserious)\n",
    "\n",
    "paste(\"Percentage of nonserious=[1,2,3] respondents\")\n",
    "as.numeric(nrow(d[d$nonserious %in%  c(1,2,3),]) / nrow(d)) * 100\n",
    "\n",
    "hist(d$nonserious, main = \"Histogram of Nonserious variable\", xlab = \"Nonserious label\", col = \"lightblue\", border = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's construct our base data set (q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base data set \n",
    "q1_data = get_data()\n",
    "\n",
    "# consider only \"always honest\" respondents \n",
    "q1_data = filter_honest(q1_data, c(5))\n",
    "\n",
    "# consider respondents with _page_timing less than equal to 30 seconds\n",
    "q1_data = filter_timing(q1_data, \"ftpolice\", 30)\n",
    "q1_data = filter_timing(q1_data, \"ftjournal\", 30)\n",
    "\n",
    "# consider only respondents with nonseriousness levels 1,2,3 \n",
    "q1_data = filter_nonserious(q1_data, c(1,2,3))\n",
    "\n",
    "nrow(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We further slice our data on the basis of very serious vs our population of serious [1,2,3] respondents\n",
    "q1_data_serious = filter_nonserious(q1_data, c(1))\n",
    "nrow(q1_data_serious)/nrow(q1_data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We notice that the very serious (nonserious=1) population is a large portion of the data we are working with.  So we will decide NOT to conduct separate tests for very serious (nonserious=1) vs semi serious (nonserious=[1,2,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we further investigate the ftpolice_skp and ftjournal_skp variables\n",
    "\n",
    "# EDA for ftpolice_skp\n",
    "paste(\"Summary for ftpolice_skp\")\n",
    "summary(q1_data$ftpolice_skp)\n",
    "\n",
    "paste(\"Percentage of non-zero ftpolice_skp\")\n",
    "as.numeric(nrow(q1_data[q1_data$ftpolice_skp %in%  c(1),]) / nrow(q1_data)) * 100\n",
    "# < 1% of the respondents chose to skip the ftpolice question. This shows the respondents are not hesitant!\n",
    "\n",
    "# EDA for ftjournal_skp\n",
    "paste(\"Summary for ftjournal_skp\")\n",
    "summary(q1_data$ftjournal_skp)\n",
    "\n",
    "paste(\"Percentage of non-zero ftjournal_skp\")\n",
    "as.numeric(nrow(q1_data[q1_data$ftjournal_skp %in%  c(1,2),]) / nrow(q1_data)) * 100\n",
    "# < 1% of the respondents chose to skip the ftjournal question. This shows the respondents are not hesitant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We conclude that there were very few (< 1%) of respondents from our base data set that chose to skip the ftpolice or ftjournal question. So we will NOT conduct further tests based on skp=0 vs all skp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Analysis of ftpolice and ftjournal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist(q1_data$ftpolice, xlab = \"ftpolice score\", main = \"Histogram of ftpolice\", col = \"lightblue\", border = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the ordinal and likert nature of the ftpolice score, we cannot construct any distribution of the variable. \n",
    "#### However, we notice a skewness in high respect for police based on the histogram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we observe there are negative values for ftjournal, which is also evident from the histogram\n",
    "\n",
    "hist(q1_data$ftjournal, xlab = \"ftjournal score\", main = \"Histogram of ftjournal\", col = \"lightblue\", border = \"black\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the ordinal and likert nature of the ftjournal score, we cannot construct any distribution of the variable. \n",
    "#### However, we notice an almost bi-modal nature in ftjournal score - people are divided on their respect levels for journalists  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we notice there are values for ftjournal < 0, so we need to remove these rows as they are missing values\n",
    "paste(\"ftjournal scores less than 0\")\n",
    "nrow(q1_data[q1_data$ftjournal < 0,])\n",
    "\n",
    "paste(\"ftjournal scores >= 0\")\n",
    "q1_data = q1_data[q1_data$ftjournal >= 0,]\n",
    "nrow(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check on having the right values for our tests\n",
    "nrow(q1_data[q1_data$ftjournal >= 0 & q1_data$ftpolice >= 0,]) == nrow(q1_data)\n",
    "nrow(q1_data[q1_data$ftjournal <= 100 & q1_data$ftpolice <= 100,]) == nrow(q1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your EDA, select an appropriate hypothesis test. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few observations:\n",
    "\n",
    "1. The measurements are likert variables, we cannot say that the difference between 5 and 6 is the same between 89 and 90. These are NOT metric values.\n",
    "2. Having said that, a score of 89 is more favorable than a score of 5 **(ordinal behavior)**.\n",
    "3. However, these are **comparable in measurement across groups** because they are measured on the SAME scale and measured against the SAME audience.\n",
    "4. The distribution of both ftpolice and ftjournal cannot be determined due to likert nature. **So we will have to use \"non parametric tests\"**.\n",
    "5. Note that we are NOT interested in \"how much more\" do US voters respect police vs journalists. We are interested in \"which group is respected more\". Specifically, **we are interested in the sign of the test** where the sign indicates which side US voters respect more. Note that because we use non-parametric signed tests, we are throwing out information of the likert scale.\n",
    "6. These are **paired measurements against the same individual across 2 groups** - journalists and policemen.\n",
    "7. Notice sample size is large, n > 40.\n",
    "8. Hence, we will conduct a paired non parametric test, specifically, the **Signed test for Dependent Samples**\n",
    "9. We **could have performed a Wilcoxon Signed-Rank test for paired data**, but that will answer the question - \"How much more / less are the police respected compared to journalists by US Voters?\" **if we could subtract these therm variables**. That answers a different question from the one being asked, although it would have more statistical power than the signed test. \n",
    "\n",
    "Assumptions:\n",
    "\n",
    "1. We can assume as per instructions in the lab that each pair of ftpolice and ftjournal, say (p, j) are IID from every other pair.\n",
    "2. We do have an ordinal scale for measurement (0 to 100 therm scale)\n",
    "\n",
    "Consequence:\n",
    "1. Because we are throwing away all our likert information, we **lose some statistical power with the signed test.**\n",
    "\n",
    "Hypothesis:\n",
    "\n",
    "1. Let plus = number of total events of seeing ftpolice > ftjournal\n",
    "2. Let minus = number of total events of seeing ftpolice < ftjournal\n",
    "3. Here, plus ~ Binomial(n, 0.5)\n",
    "\n",
    "**$H_0$: Prob(plus) = Prob(minus)**\n",
    "\n",
    "**$H_a$: Prob(plus) $\\ne$ Prob(minus)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_hat = nrow(q1_data[q1_data$ftpolice == q1_data$ftjournal,])\n",
    "plus_hat = nrow(q1_data[q1_data$ftpolice > q1_data$ftjournal,])\n",
    "minus_hat = nrow(q1_data[q1_data$ftpolice < q1_data$ftjournal,])\n",
    "total_hat = as.numeric(equal_hat + plus_hat + minus_hat)\n",
    "# ignore equal scores of ftjournal and ftpolice for binomial test\n",
    "n = total_hat - equal_hat\n",
    "\n",
    "paste(\"ftpolice == ftjournal:\", equal_hat)\n",
    "paste(\"ftpolice > ftjournal:\", plus_hat)\n",
    "paste(\"ftpolice < ftjournal:\", minus_hat)\n",
    "paste(\"total:\", total_hat)\n",
    "paste(\"total - equal:\", n)\n",
    "\n",
    "# binomial test\n",
    "p = 0.5\n",
    "mean = n * p\n",
    "threshold = abs(plus_hat - mean)\n",
    "paste(\"The mean:\", mean)\n",
    "paste(\"The threshold:\", threshold)\n",
    "# p value is prob that |plus - mean| >= threshold\n",
    "# to find p value\n",
    "# P(plus - 910.5 >= 122.5) and P(910.5 - plus >= 122.5)\n",
    "# P(plus >= 1033) and P(plus <= 788)\n",
    "\n",
    "binom.test(x = c(plus_hat, minus_hat), n, p = 0.5, alternative = c(\"two.sided\"), conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above shows that we reject the null hypothesis as the p value is very small at 5% level of significance. We see that probabilities of the number of successes in the 2 groups is NOT equal.\n",
    "\n",
    "#### We see probability of success is around 56%. This implies that the US voters do like policemen more than journalists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infact, if we did the test one sided, where the alternative is that \n",
    "# Prob(# fav. ftpolice scores) > Prob(# fav. ftjournal scores) \n",
    "binom.test(x = c(plus_hat, minus_hat), n, p = 0.5, alternative = c(\"greater\"), conf.level = 0.95)\n",
    "# this further shows that the alternative hypothesis is favorable, \n",
    "# where probability of police respect cases is more than probability of journalism respect cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Effect Size For Signed Test**\n",
    "\n",
    "1. We can think of the proportion of police population as the effect size\n",
    "2. We can also think of (plus_hat - minus_hat) / n as the effect size\n",
    "3. Since n is large, the effect size is actually significant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_hat/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plus_hat - minus_hat)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can conclude that there is a real difference between the respect levels for police vs journalists. US voters respect the police more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Are Republican voters older or younger than Democratic voters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce your topic briefly.  (5 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables operationized\n",
    "There are four variables I am using to validate the hypothesis that Republican voters are younger than Democrat voters\n",
    "<dl>\n",
    "  <dt>honest</dt>\n",
    "  <dd><em>Question: </em>\"How often would you say you answered the questions honestly on this survey.\"\n",
    "  <br>The range of responses are 1-5 which corelate from Never - Always. I have restricted the observations to only those who answer <em>always (5)</em></dd>\n",
    "  <br>\n",
    "  <dt>pid1r</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Republican, a Democrat, an\n",
    "independent, or what?\"</dd>\n",
    "  <br>  \n",
    "  <dt>pid1d</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Democrat, a Republican, an\n",
    "independent, or what?\"<br>\n",
    "      As you can see this is essentially the same question with the just the <em>order</em> of the party name changed. The two responses I am interested in are 1 or 2. This corresponds to the first or second party mentioned in the questions\n",
    "  </dd>\n",
    "  <br>\n",
    "    \n",
    "  <dt>birthyr</dt>\n",
    "  <dd><em>Question: </em>“In what year were you born?”<br>\n",
    "      The response to this question was the year of birth. Since this survey was taken in 2018, for calculation of age, to determine age, we used:\n",
    "      \n",
    "```python\n",
    "2018 - birthyr \n",
    "```\n",
    "  </dd>\n",
    "  <dt>Gaps</dt>\n",
    "  <dd>1. There is an assumption that a \"Republican voter\" (i.e. someone who voted for the Republican candidate) also identfies as a Republican, and similarly for Democrat voter. It is quite likely that many who identify with one party, can vote for another party</dd>\n",
    "  <br>\n",
    "    <dd>2. There is another variable <em>nonserious</em> that while interesting, brought with it social implications that were beyond the scope for this exercise and I decided to ignore that variable</dd>\n",
    "    \n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform an exploratory data analysis (EDA) of the relevant variables. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "# apply honestly filter\n",
    "hon_respondents = data[data$honest == 5,]\n",
    "paste(cat(\"Number of honest respondents: :\", nrow(hon_respondents)))\n",
    "\n",
    "honest.code <- c(Never=1, `Some of the time`=2, `Half of the time`=3, `Most of the time`=4,  Always=5)\n",
    "h_responses = names(honest.code)[match(data$honest, honest.code)]\n",
    "paste(cat(\"First 6 reponses in honest variable are:\",\"\\n\",head(h_responses)))\n",
    "\n",
    "pid1d.code <- c( Democrat=1, Republican=2, independent=3, 'something else'=4)\n",
    "pid1r.code <- c( Republican=1, Democrat=2, independent=3, 'something else'=4)\n",
    "p1did_responses = names(pid1d.code)[match(data$pid1d, pid1d.code)]\n",
    "p1dir_responses = names(pid1r.code)[match(data$pid1r, pid1r.code)]\n",
    "\n",
    "paste(cat(\"First 6 reponses in pid1d are: \", head(p1did_responses)))\n",
    "paste(cat(\"First 6 reponses in pid1r are:\", head(p1dir_responses)))\n",
    "paste(cat(\"Ages of first 6 respondents calculated to be: \", head(2018-data[, c(\"birthyr\")])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your EDA, select an appropriate hypothesis test.  (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_honest_reps = rbind(data[data$pid1r==1 & data$honest==5,], data[data$pid1d==2 & data$honest==5,])\n",
    "all_honest_dems = rbind(data[data$pid1r==2 & data$honest==5,], data[data$pid1d==1 & data$honest==5,])\n",
    "paste(cat(\"Number of observerations or Republicans: \", nrow(all_honest_reps)))\n",
    "paste(cat(\"Number of observerations or Democrats: \", nrow(all_honest_dems)))\n",
    "\n",
    "\n",
    "ages_of_reps = 2018-all_honest_reps[,c('birthyr')]\n",
    "ages_of_dems = 2018-all_honest_dems[,c('birthyr')]\n",
    "hist(ages_of_reps, main = \"Histogram of age distribution of Republican voters\", xlab = \"Age\", col=\"red\")\n",
    "hist(ages_of_dems, main = \"Histogram of age distribution of Democrat voters\", xlab = \"Age\", col=\"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing a Levene's to check the group variances\n",
    "\n",
    "$H_0$ The group variances are equal\n",
    "\n",
    "$H_a$ The group variances are not equal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = c(ages_of_dems, ages_of_reps)\n",
    "group = as.factor(c(rep(1, length(ages_of_dems)), rep(2, length((ages_of_reps))) ))\n",
    "leveneTest(y, group, center=\"mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result of the Levene's Test, ' We fail to reject the null hypothesis at \n",
    "the 0.05 significance level since the value of the Levene test statistic is less \n",
    "than the critical value, hence we assume the varainces are equal and go with two tail 2 sample t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data are normally distributed, we can use a parametric test and since we are comparing the means of two samples, we can use the Welches Two Sample t-test (IOW, \"unpaired\" or \"independent samples\" t-test)\n",
    "\n",
    "\n",
    "$\\mu_d$ is the population mean age of the Democrats \n",
    "\n",
    "$\\mu_r$ is the population mean age of the Republicans  \n",
    "\n",
    "**$H_0$: $\\mu_d = \\mu_r$**\n",
    "\n",
    "**$H_a$: $\\mu_d \\ne \\mu_r$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(ages_of_dems, ages_of_reps, alternative = \"two.sided\", 0, paired = FALSE, var.equal = TRUE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this test, we can say with 95% confidence that there is no significant difference between the means of the ages of the Republican voters and the Democratic voters\n",
    "\n",
    "The difference of the mean can be as low as -2.40 or has high as 1.19.\n",
    "\n",
    "The sample means are 52.33 for republicans and 52.92 for democrats.\n",
    "    \n",
    "Based on this we <em>do not have enough evidence to reject the null hypothesis</em> that there is no difference between the means.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen.d(ages_of_dems, ages_of_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CohensD test returns an estimate of 0.036 which indicates that the effect is negligible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on this study we can conclude that there is no significant difference between the mean ages of the Republicans and the Democrats.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Do a majority of independent voters believe that the federal investigations of Russian election interference are baseless?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce your topic briefly.  (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how your variables are operationalized. Comment on any gaps that you can identify between your operational definitions and the concepts you are trying to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables operationized\n",
    "There are seven variables we are using to validate if the independent voters believe that the federal investigations of Russian election interference were baseless.\n",
    "<dl>\n",
    "  <dt>honest</dt>\n",
    "  <dd><em>Question: </em>\"How often would you say you answered the questions honestly on this survey.\"\n",
    "  <br>The range of responses are 1-5 which corelate from Never - Always. We have restricted the observations to remove those who answered <em>Never (1)</em></dd>\n",
    "  <br>\n",
    "    \n",
    "  <dt>nonserious</dt>\n",
    "  <dd><em>Question: </em>\"We sometimes find people don't always take surveys seriously, instead providing funny or\n",
    "insincere answers. How often would you say that you were not serious in answering\n",
    "questions on this survey?\"\n",
    "  <br>The range of responses are 1-5 which corelate from Never - Always. We have restricted the observations to remove those who answered <em>Always (5)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  <dt>pid1r</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Republican, a Democrat, an\n",
    "independent, or what?\"</dd>\n",
    "  <br>  \n",
    "  <dt>pid1d</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Democrat, a Republican, an\n",
    "independent, or what?\"<br>\n",
    "      As you can see this is essentially the same question with the just the <em>order</em> of the party name changed. The response we are interested for both questions is 3 i.e. Independent.\n",
    "  </dd>\n",
    "  <br>\n",
    "  \n",
    "   <dt>pid7x</dt>\n",
    "  <dd><em>Question: </em>\"Party ID summary\"\n",
    "  <br>The range of responses are from -7 to 7. We have restricted the observations to include those who answered <em>Independent (4)</em></dd>\n",
    "  <br>  \n",
    "    \n",
    "   <dt>russia16</dt>\n",
    "  <dd><em>Question: </em>\"Do you think the Russian government probably interfered in the 2016 presidential election\n",
    "to try to help Donald Trump win, or do you think this probably did not happen?\"\n",
    "  <br>We are checking their view on Russia's involvement, on the sample set we got from above 5 variables<em>This probably did not happen(2)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  <dt>coord16</dt>\n",
    "  <dd><em>Question: </em>\"Do you think Donald Trump’s 2016 campaign probably coordinated with the Russians, or do\n",
    "you think his campaign probably did not do this?\"\n",
    "  <br>We are checking their view on Russia's involvement, on the sample set we got from first 5 variables <em>Probably did not (2)</em></dd>\n",
    "  <br>\n",
    "    \n",
    " \n",
    "  <dt>Gaps</dt>\n",
    "  <dd>1. There is an assumption that a \"Independent voter\" (i.e. someone who is neither Republican nor Democrat) is indeed Independent and doesn't have bias in his opinion. </dd>\n",
    "  <br>\n",
    "    <dd>2. The variables <em>honest</em> and <em>nonserious</em> are both very subjective to people. We are including people in our sample space who might or might not be honest/nonserious. We have only neglected the people who were clear they didn't take the questionaire seriousloy.</dd>\n",
    "    \n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform an exploratory data analysis (EDA) of the relevant variables. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = get_data()\n",
    "\n",
    "unique(data$russia16)\n",
    "unique(data$coord16)\n",
    "\n",
    "#Replace -7 with 0 and create two new columns \n",
    "data1 <- mutate(\n",
    "  data, russia16_n = as.numeric(ifelse(substr(data$russia16,0,1) == \"-\", 0, substr(data$russia16,0,1))),\n",
    "  coord16_n = as.numeric(ifelse(substr(data$coord16,0,1) == \"-\", 0, substr(data$coord16,0,1))))\n",
    "\n",
    "# Checking all 3 tags and finding the Independent voters. Tried finding common of all 3, but found no one \n",
    "data2 <- mutate(subset(data1,substr(pid7x,0,1) == '4' | substr(pid1d,0,1) == '3' | substr(pid1r,0,1) == '3' , \n",
    "         select = c(pid7x,pid1d,pid1r,russia16_n,coord16_n)), indep_voters = 'Independent')\n",
    "\n",
    "#Checking honesty and seriousness as well and who didnt skip answer about Russia involvement question\n",
    "data3 <- mutate(subset(data1,(substr(pid7x,0,1) == '4' | substr(pid1d,0,1) == '3' | substr(pid1r,0,1) == '3') & \n",
    "        (honest != '1' & nonserious != '5') & (russia16_n != '0' & coord16_n != '0'), \n",
    "        select = c(pid7x,pid1d,pid1r,russia16_n,coord16_n, honest, nonserious)), indep_voters = 'Independent')\n",
    "\n",
    "\n",
    "data4 <- data3\n",
    "\n",
    "#Adding a new column as Russian view where 2 implies people didnt think Russia was involved\n",
    "data4$russ_view <- ifelse((data3$russia16_n == '2' | data3$coord16_n == '2'), 1, 0)\n",
    "\n",
    "data4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your EDA, select an appropriate hypothesis test.  (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hypothesis:\n",
    "\n",
    "Do a majority of independent voters believe that the federal investigations of Russian election interference are baseless\n",
    "\n",
    "Let R1 = Number of Independent voters believe Russia was not involved\n",
    "\n",
    "Let R2 = Number of Independent voters believe Russia was involved\n",
    "\n",
    "**$H_0$ = Null hypothesis, Prob(R1) = Prob(R2)**\n",
    "\n",
    "**$H_a$ = Alternative hypothesis, Prob(R1) $\\ne$ Prob(R2)** \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample size\n",
    "n <- length(data4$russ_view)\n",
    "russ_no = nrow(data4[data4$russ_view == 1,])\n",
    "russ_yes = nrow(data4[data4$russ_view == 0,])\n",
    "\n",
    "paste(\"Number of people believe Russia was not involved (R1): \", russ_no)\n",
    "paste(\"Number of people believe Russia was involved (R2):\", russ_yes)\n",
    "\n",
    "\n",
    "#We can do a z.test here with mu=0.5 but since the russ_view is a Binamial experiment here, \n",
    "#we can use the binom.test which is even more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.test(x = c(russ_no, russ_yes), n, p = 0.5, alternative = c(\"two.sided\"), conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 811 Independent Voters, 431 believe that federal investigations of Russian election interference are baseless and Russia was not involved.\n",
    "\n",
    "Based on our binom.test we see that the p-value is 0.079 >0.05 which implies **we fail to reject the Null Hypothesis** \n",
    "\n",
    "Hence, we **dont** have enough statistical significance to say that a majority of Independent voters beleive that\n",
    "the federal investigations of Russian election interference are baseless.\n",
    "\n",
    "Which implies, **that Russia may or may not have been involved.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cohend test**\n",
    "\n",
    "Since we dont have a statistcially significant result, no point checking its practical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Was anger or fear more effective at driving increases in voter turnout from 2016 to 2018?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce your topic briefly.  (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use turnout18 and turnout16 as the variables to measure voter turnout in 2018 and 2016 respectively.\n",
    "\n",
    "**turnout18** <br/>\n",
    "In the election held on November 6, did you definitely vote in person on election day, vote in\n",
    "person before Nov 6, vote by mail, did you definitely not vote, or are you not completely sure\n",
    "whether you voted in that election?\n",
    "1. Definitely voted in person on Nov 6 (1)\n",
    "2. Definitely voted in person, before Nov 6 (2)\n",
    "3. Definitely voted by mail (3)\n",
    "4. Definitely did not vote (4)\n",
    "5. Not completely sure (5)\n",
    "\n",
    "A subset of these voters with turnout18=[1,2,3] are \"definitive voters\"\n",
    "\n",
    "**turnout16** <br/>\n",
    "In 2016, the major candidates for president were Donald Trump for the Republicans and\n",
    "Hillary Clinton for the Democrats. In that election, did you definitely vote, definitely not vote,\n",
    "or are you not completely sure whether you voted?\n",
    "\n",
    "1. Definitely voted (1)\n",
    "2. Definitely did not vote (2)\n",
    "3. Not completely sure (3)\n",
    "\n",
    "**Variables for Anger and Fear**\n",
    "\n",
    "These are all likert variables on a scale from 1-5, with 1=Never and 5=Always\n",
    "\n",
    "*Generally speaking, how do you feel about the way things are going in the country these days?*\n",
    "1. geangry\n",
    "2. geafraid\n",
    "\n",
    "*Think about Donald Trump. How often would you say you’ve felt each of the following ways because of the\n",
    "kind of person Donald Trump is or because of something he has done?* \n",
    "\n",
    "1. dtangry\n",
    "2. dtafraid\n",
    "\n",
    "Similar to question 1, we consider respondents who are always honest (5), and mostly serious (1,2,3). This is needed because we want to gauge additional feelings of \"anger\" and \"fear\" from the respondents. Its important that they answer to these feelings with honesty and sincerity, else we dont know if they were actually angry or fearful.\n",
    "\n",
    "Looking at the page_timing variables for turnout (turnout18_page_timing, turnout16_page_timing) and the skp variables for turnout (turnout18_skp and turnout16_skp) - we observe mostly everyone answered the question without skipping (few observations with skp=1) and very few took more than 20 seconds to answer the turnout questions. We will NOT seggregate tests based on these variables\n",
    "\n",
    "Assumption:\n",
    "\n",
    "While the meaning \"anger\" and \"fear\" variables may vary between respondents, but for a single respondent, the anger and fear measurement can be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform an exploratory data analysis (EDA) of the relevant variables. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do a preliminary analysis - how much more was the voter count in 2018 vs 2016, we observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_data()\n",
    "# consider definitive voters, turnout18=[1,2,3]\n",
    "# also consider respondents who are not sure if they voted in 2018, turnout18=5\n",
    "# consider respondents who have definitely voted in 2016, as per turnout16=1\n",
    "# This will give us the true voter turnout in 2016 and 2018\n",
    "d_v18 = filter_col(d, \"turnout18\", c(1,2,3,5))\n",
    "d_v16 = filter_col(d, \"turnout16\", c(1))\n",
    "nrow(d_v18) - nrow(d_v16)\n",
    "\n",
    "d_v18 = filter_col(d, \"turnout18\", c(1,2,3))\n",
    "nrow(d_v18) - nrow(d_v16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe there's not much of a difference in the turnout amongst people who definitely voted in 2018 vs 2016. **There was only 1 more vote amongst the \"definitive voters\". If we include the voters who are not sure if they voted in 2018, the difference is 115.** What happens if we re-do the analysis with filters like honesty and nonserious applied?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_data()\n",
    "d = filter_honest(d, c(5))\n",
    "d = filter_nonserious(d, c(1,2,3))\n",
    "d_v18 = filter_col(d, \"turnout18\", c(1,2,3,5))\n",
    "d_v16 = filter_col(d, \"turnout16\", c(1))\n",
    "nrow(d_v18) - nrow(d_v16)\n",
    "\n",
    "d_v18 = filter_col(d, \"turnout18\", c(1,2,3))\n",
    "nrow(d_v18) - nrow(d_v16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that, overall, amongst honest and serious respondents, 19 more people voted in 2018 compared to 2016. If we only include definitive voters in 2018, we find more people voted in 2016 compared to 2018!\n",
    "\n",
    "It is possible that these effects are being observed due to a lower turnout during mid elections (2018) vs during a full term election (2016)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shift our focus to respondents who **didn't** vote in 2016, and **did** vote in 2018. The \"increase in participation from the respondents who didn't vote in 2016 and did vote in 2018\" is what the question asks for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_data = get_data()\n",
    "q4_data = filter_honest(q4_data, c(5))\n",
    "q4_data = filter_nonserious(q4_data, c(1,2,3))\n",
    "# get non voters in 2016\n",
    "q4_data = filter_col(q4_data, \"turnout16\", c(2))\n",
    "q4_data_v16_not = q4_data\n",
    "\n",
    "# out of these non voters in 2016, what percentage voted in 2018?\n",
    "q4_data_v18_nv16 = filter_col(q4_data_v16_not, \"turnout18\", c(1,2,3))\n",
    "100 * nrow(q4_data_v18_nv16) / nrow(q4_data_v16_not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that **17% of honest and serious respondents who didn't vote in 2016 ended up voting in 2018.** We are interested in what drove 17% of these non voters (2016) to vote in 2018. We explore this via our fear and anger variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any invalid responses for anger and fear\n",
    "q4_data_v18_nv16 = filter_col(q4_data_v18_nv16, \"geangry\", c(1,2,3,4,5))\n",
    "q4_data_v18_nv16 = filter_col(q4_data_v18_nv16, \"geafraid\", c(1,2,3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(q4_data_v18_nv16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 61 respondents (honest and serious) who didnt vote in 2016, but voted in 2018. Further analysis will be on these 61 voters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(q4_data_v18_nv16$geangry, main = \"Histogram of geangry variable\", xlab = \"Geangry label\", col = \"lightblue\", border = \"black\")\n",
    "# hist(q4_data_v18_nv16$dtangry, main = \"Histogram of dtangry variable\", xlab = \"Dtangry label\", col = \"lightblue\", border = \"black\")\n",
    "hist(q4_data_v18_nv16$geafraid, main = \"Histogram of geafraid variable\", xlab = \"Geafraid label\", col = \"lightblue\", border = \"black\")\n",
    "# hist(q4_data_v18_nv16$dtafraid, main = \"Histogram of dtafraid variable\", xlab = \"Dtafraid label\", col = \"lightblue\", border = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we see several cases of \"-1\" (legitimate skip) response for the **dtangry and dtafraid** variables for these 61 respondents. So we will only use **geangry and geafraid** variables for measuring anger and fear in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Percentage of dtafraid where question was skipped\")\n",
    "100 * nrow(q4_data_v18_nv16[q4_data_v18_nv16$dtafraid == -1,]) / nrow(q4_data_v18_nv16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Percentage of dtangry where question was skipped\")\n",
    "100 * nrow(q4_data_v18_nv16[q4_data_v18_nv16$dtangry == -1,]) / nrow(q4_data_v18_nv16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your EDA, select an appropriate hypothesis test. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few observations:\n",
    "\n",
    "1. The measurements of fear and anger are likert variables. These are NOT metric values.\n",
    "2. However, these are **comparable in measurement across feelings** because they are measured on the SAME scale and measured against the SAME audience. So a score of geafraid=5 and geangry=1 will show that respondent is more afraid than angry.\n",
    "4. The distribution of both geafraid and geangry cannot be determined due to likert nature. **So we will have to use \"non parametric tests\"**.\n",
    "5. Note that we are NOT interested in \"how much more\" did anger or fear influence increase in voter turnout. We are interested in \"which feeling dominated the voter turnout increase in 2018\". Specifically, **we are interested in the sign of the test** where the sign indicates which feeling is dominant. Note that because we use non-parametric signed tests, we are throwing out information of the likert scale (how much feeling).\n",
    "6. These are **paired measurements against the same individual across 2 feelings** - geangry and geafraid.\n",
    "7. Notice sample size is large (61), so n > 40.\n",
    "8. Hence, we will conduct a paired non parametric test, specifically, the **Signed test for Dependent Samples**\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "1. We can assume as per instructions in the lab that each pair of geafraid and geangry, say (afr, ang) are IID from every other pair.\n",
    "2. We do have an ordinal scale for measurement (0 to 5).\n",
    "\n",
    "Consequence:\n",
    "1. Because we are throwing away all our likert information, we **lose some statistical power with the signed test.**\n",
    "\n",
    "Hypothesis:\n",
    "\n",
    "1. Let plus = number of total events of seeing geangry > geafraid\n",
    "2. Let minus = number of total events of seeing geangry < geafraid\n",
    "3. Here, plus ~ Binomial(n, 0.5)\n",
    "\n",
    "**$H_0$: Prob(plus) = Prob(minus)**\n",
    "\n",
    "**$H_a$: Prob(plus) $\\ne$ Prob(minus)**\n",
    "\n",
    "**Note that we are answering the following question: Out of the voters who didn't vote in 2016, but did vote in 2018, was it fear or anger that motivated them to vote?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_hat = nrow(q4_data_v18_nv16[q4_data_v18_nv16$geangry == q4_data_v18_nv16$geafraid,])\n",
    "plus_hat = nrow(q4_data_v18_nv16[q4_data_v18_nv16$geangry > q4_data_v18_nv16$geafraid,])\n",
    "minus_hat = nrow(q4_data_v18_nv16[q4_data_v18_nv16$geangry < q4_data_v18_nv16$geafraid,])\n",
    "total_hat = as.numeric(equal_hat + plus_hat + minus_hat)\n",
    "# ignore equal scores of geangry and geafraid for binomial test\n",
    "n = total_hat - equal_hat\n",
    "\n",
    "paste(\"geangry == geafraid:\", equal_hat)\n",
    "paste(\"geangry > geafraid:\", plus_hat)\n",
    "paste(\"geangry < geafraid:\", minus_hat)\n",
    "paste(\"total:\", total_hat)\n",
    "paste(\"total - equal:\", n)\n",
    "\n",
    "# binomial test\n",
    "p = 0.5\n",
    "mean = n * p\n",
    "threshold = abs(plus_hat - mean)\n",
    "paste(\"The mean:\", mean)\n",
    "paste(\"The threshold:\", threshold)\n",
    "binom.test(x = c(plus_hat, minus_hat), n, p = 0.5, alternative = c(\"two.sided\"), conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are only 32 values, after disregarding the respondents who are equally afraid or angry. Out of these 32 values, 16 are more angry and 16 are more afraid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the binomial test that the alternative hypothesis is rejected as voters are equally likely to be afraid or angry. **This shows that neither of these feelings influences them more to come and vote in 2018**. There is no effect size to be calculated as there is no effect to be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its important to note that we have had to **throw out almost half (29) of our 61 variables** in the binom test because geangry == geafraid. This shows that there were significant number of people who had the same scores for anger and fear. The question then becomes - are \"geangry\" and \"geafraid\" independent of each other? Or are they expressing similar feelings? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Select a fifth question that you believe is important for understanding the behavior of voters: Did women voters who voted in 2018 become more liberal(Democrat) than 2016?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearly argue for the relevance of this question. (10 points)\n",
    "In words, clearly state your research question and argue why it is important for understanding the recent voting behavior. Explain it as if you were presenting to an audience that includes technical and non technical members.\n",
    "\n",
    "Explain how your variables are operationalized. Comment on any gaps that you can identify between your operational definitions and the concepts you are trying to study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables operationized\n",
    "There are seven variables I am using to validate the hypothesis that the federal investigations of Russian election interference are baseless.\n",
    "<dl>\n",
    "  <dt>honest</dt>\n",
    "  <dd><em>Question: </em>\"How often would you say you answered the questions honestly on this survey.\"\n",
    "  <br>The range of responses are 1-5 which corelate from Never - Always. We have restricted the observations to people who were always honest<em>Always (5)</em></dd>\n",
    "  <br>\n",
    "    \n",
    "  <dt>gender</dt>\n",
    "  <dd><em>Question: </em>\"Are you male or female?\"\n",
    "  <br>We are just interested in Female opinion<em>Female (2)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  \n",
    "   <dt>turnout18</dt>\n",
    "  <dd><em>Question: </em>\"In the election held on November 6, did you definitely vote in person on election day, vote in person before Nov 6, vote by mail, did you definitely not vote, or are you not completely sure whether you voted in that election?\"\n",
    "  <br>Range of values between 1 to 5. Where 1,2,3 are people who voted for sure.<em>Defintely voted by either means (1,2,3)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  <dt>turnout16</dt>\n",
    "  <dd><em>Question: </em>\"In 2016, the major candidates for president were Donald Trump for the Republicans and\n",
    "Hillary Clinton for the Democrats. In that election, did you definitely vote, definitely not vote,\n",
    "or are you not completely sure whether you voted?\"\n",
    "  <br>Range of values between 1 to 3. <em>Defintely voted (1)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  <dt>vote16</dt>\n",
    "  <dd><em>Question: </em>\"In the 2016 presidential election, who did you vote for? Donald Trump, Hillary Clinton, or\n",
    "someone else?\"\n",
    "  <br>Range of values between 1 to 3. We are checking if they voted for Donald(1) or Hillary (2) <em>Defintely voted to either one (1,2)</em></dd>\n",
    "  <br>\n",
    "  \n",
    "  <dt>pid1r</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Republican, a Democrat, an\n",
    "independent, or what?\"</dd>\n",
    "  <br>  \n",
    "  <dt>pid1d</dt>\n",
    "  <dd><em>Question: </em>\"Generally speaking, do you usually think of yourself as a Democrat, a Republican, an\n",
    "independent, or what?\"<br>\n",
    "      As you can see this is essentially the same question with the just the <em>order</em> of the party name changed. The response I am interested is for both questions is 3 i.e. Independent.\n",
    "  </dd>\n",
    "  <br>\n",
    "  \n",
    " \n",
    " \n",
    "  <dt>Gaps</dt>\n",
    "  <dd>1. We are ignoring the people who are not sure in their answers for all the possible options. </dd>\n",
    "  <br>\n",
    "    <dd>2. The variables <em>honest</em> and <em>nonserious</em> are both very subjective to people. We are including people in our sample space who are defintely honest and we are neglecting nonserious in this question.</dd>\n",
    "    \n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform EDA and select your hypothesis test (5 points)\n",
    "\n",
    "Perform an exploratory data analysis (EDA) of the relevant variables.\n",
    "\n",
    "This should include a treatment of non-response and other special codes, basic sanity checks, and a justification for any values that are removed. Use visual tools to assess the relationship among your variables and comment on any features you find.\n",
    "\n",
    "Based on your EDA, select an appropriate hypothesis test. Explain why your test is the most appropriate choice. List and evaluate all assumptions for your test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = read.csv( \"D:\\\\data\\\\anes\\\\anes_pilot_2018.csv\")\n",
    "data = get_data()\n",
    "\n",
    "#Filtering out only honest women\n",
    "hf = data[data$gender == 2 & data$honest == 5,]\n",
    "# only consider those who voted for sure \n",
    "f18V = hf[hf$turnout18 < 4,]\n",
    "\n",
    "#Create new columns if they were democrat or republican in 2016 and 2018 \n",
    "#Based on whom they voted in 2016 and their political view in 2018\n",
    "\n",
    "f18V = within(f18V, {\n",
    "  statedRep = ifelse((pid1d==2 | pid1r==2), 1, 0)\n",
    "  statedDem = ifelse((pid1d==1 | pid1r==1), 1, 0)\n",
    "  votedR16 = ifelse(turnout16==1 & vote16 ==1,1,0)\n",
    "  votedD16 = ifelse(turnout16==1 & vote16 ==2,1,0)\n",
    "  votedO16 = ifelse(turnout16 != 1 | vote16 > 2,1,0)\n",
    "})\n",
    "# determine the women who flipped their opinion or who were unchanged\n",
    "f18V = within(f18V, {\n",
    "  change18 =\n",
    "    #no change in affliliation\n",
    "    case_when((votedR16  == 1 & statedRep == 1) |(votedD16 == 1 & statedDem == 1) ~ 0,\n",
    "              # flipped to R or new R\n",
    "              (votedD16 == 1 & statedRep == 1) | (votedO16 == 1 & statedRep == 1) ~ 1,\n",
    "              # flipped to D or new D\n",
    "              (votedR16 == 1 & statedDem == 1) | (votedO16 == 1 & statedDem == 1) ~ 2,\n",
    "              #default\n",
    "              TRUE ~ 3)\n",
    "})\n",
    "f18Vpartial = f18V[,c( \"turnout18\", \"votedR16\", \"votedD16\",\"votedO16\",\"statedDem\", \"statedRep\", \"change18\")]\n",
    "# limit to just those who flipped to R or to D\n",
    "\n",
    "f18flippedDorR = f18Vpartial[f18Vpartial$change18 == 1 |f18Vpartial$change18 == 2, ]\n",
    "\n",
    "flippedToR = nrow(f18flippedDorR[f18flippedDorR$change18 == 1,])\n",
    "flippedToD = nrow(f18flippedDorR[f18flippedDorR$change18 == 2,])\n",
    "\n",
    "\n",
    "nrow(f18Vpartial)\n",
    "\n",
    "head(f18Vpartial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct your test. (2 points)\n",
    "\n",
    "Explain (1) the statistical significance of your result, and (2) the practical significance of your result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\n",
    "W1: Women voters who are Democrats\n",
    "\n",
    "W2: Women voters who are Republicans\n",
    "\n",
    "**$H_0$ = Null hypothesis, Prob(W1) = Prob(W2)**\n",
    "\n",
    "**$H_a$ = Alternative hypothesis, Prob(W1) $\\ne$ Prob(W2)** \n",
    "\n",
    "This is not continuous (numeric) therefore cannot do a t test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two tail test\n",
    "binom.test(x = c(flippedToR, flippedToD), n = nrow(f18flippedDorR), p = 0.5, alternative = c(\"two.sided\"), conf.level = 0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of success not equal to 0.5 and Therefore there was a flip to one side over the other\n",
    "\n",
    "But since p is 0.3492 > 0.05, Hence **we fail to reject the null Hypothesis**\n",
    "Hence we can't say with statistical significance that there was an increase in women who were democrats or republican."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is higher than 0.05, this is not statistically significant\n",
    "\n",
    "And Hence no point checking its practical significance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion (3 points)\n",
    "\n",
    "Clearly state the conclusion of your hypothesis test and how it relates to your research question.\n",
    "\n",
    "Finally, briefly present your conclusion in words as if you were presenting to an audience that includes technical and non technical members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So the conclusion is that we cannot say for sure if there were more women Democrats in 2018 compared to 2016. We cannot say for sure if women became more liberal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
